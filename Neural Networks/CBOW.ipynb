{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-12-09T15:42:30.890422Z",
          "iopub.status.busy": "2021-12-09T15:42:30.890036Z",
          "iopub.status.idle": "2021-12-09T15:42:37.774794Z",
          "shell.execute_reply": "2021-12-09T15:42:37.774062Z",
          "shell.execute_reply.started": "2021-12-09T15:42:30.890331Z"
        },
        "id": "4YW3_F8rldIa",
        "outputId": "ae456f40-d63e-4dd8-df23-a957efbee341",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-03 00:34:51.737654: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-03 00:34:53.732243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
            "2022-12-03 00:34:53.732423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
            "2022-12-03 00:34:53.732441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python.keras.models import Model\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import re\n",
        "import nltk\n",
        "from preprocess import *\n",
        "from models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2021-12-09T15:42:52.454527Z",
          "iopub.status.busy": "2021-12-09T15:42:52.453714Z",
          "iopub.status.idle": "2021-12-09T15:43:01.326923Z",
          "shell.execute_reply": "2021-12-09T15:43:01.326227Z",
          "shell.execute_reply.started": "2021-12-09T15:42:52.454487Z"
        },
        "id": "EqAWwkLNldId",
        "outputId": "44452f81-0189-4209-b5aa-03693ad99cad",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"questions.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "execution": {
          "iopub.execute_input": "2021-12-07T01:21:29.482516Z",
          "iopub.status.busy": "2021-12-07T01:21:29.482071Z",
          "iopub.status.idle": "2021-12-07T01:21:29.56485Z",
          "shell.execute_reply": "2021-12-07T01:21:29.564017Z",
          "shell.execute_reply.started": "2021-12-07T01:21:29.482481Z"
        },
        "id": "8emCCiYnldIe",
        "outputId": "b3855e9f-7ee6-456f-e893-d144e9f95c0c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# question_1, question_2 = df['question1'].to_list(), df['question2'].to_list()\n",
        "# is_duplicate = df['is_duplicate'].to_list()\n",
        "# q1_preprocessed, q2_preprocessed = preprocess_neural(question_1, question_2, is_duplicate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oxabKDHWldIf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(\"preprocessed_neural.csv\")\n",
        "q1_preprocessed, q2_preprocessed, is_duplicate = df1['question1'].to_list(), df1['question2'].to_list(), df1['is_duplicate'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KkTq2aVsldIf",
        "outputId": "15a23b0b-3a5b-40fc-c0da-02db2a2a55d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>step step guide invest share market india</td>\n",
              "      <td>step step guide invest share market</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>story kohinoor kohinoor diamond</td>\n",
              "      <td>would happen indian government stole kohinoor ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>increase speed internet connection using vpn</td>\n",
              "      <td>internet speed increased hacking dns</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mentally lonely solve</td>\n",
              "      <td>find remainder math2324math divided 2423</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
              "      <td>fish would survive salt water</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           question1  \\\n",
              "0          step step guide invest share market india   \n",
              "1                    story kohinoor kohinoor diamond   \n",
              "2       increase speed internet connection using vpn   \n",
              "3                              mentally lonely solve   \n",
              "4  one dissolve water quikly sugar salt methane c...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0                step step guide invest share market             0  \n",
              "1  would happen indian government stole kohinoor ...             0  \n",
              "2               internet speed increased hacking dns             0  \n",
              "3           find remainder math2324math divided 2423             0  \n",
              "4                      fish would survive salt water             0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVvIXaFrldIf"
      },
      "source": [
        "Acquired Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bDZBf1IYldIh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "MAX_NB_WORDS = 200000\n",
        "tokenizer = Tokenizer(num_words = MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(list(df1['question1'].values.astype(str))+list(df1['question2'].values.astype(str)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "30CJCOxCldIh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "q1_sequence = tokenizer.texts_to_sequences(df['question1'].values.astype(str))\n",
        "q1_sequence = pad_sequences(q1_sequence, maxlen = 30, padding='post')\n",
        "\n",
        "q2_sequence = tokenizer.texts_to_sequences(df['question2'].values.astype(str))\n",
        "q2_sequence = pad_sequences(q2_sequence, maxlen = 30, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cmTi_Uj-ldIi"
      },
      "outputs": [],
      "source": [
        "windex = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uALoEDoIldIj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "embedding_index = {}\n",
        "with open('glove.6B.300d.txt','r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:], 'float32')\n",
        "        embedding_index[word] = vectors\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN9y4QPNldIj",
        "outputId": "05ff7638-79f4-46f2-b866-c9d3637cc336",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(108101, 300)\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = np.random.random((len(windex)+1, 300))\n",
        "\n",
        "for word, i in windex.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ka7Yh5wdldIk"
      },
      "outputs": [],
      "source": [
        "q1_embeddings = []\n",
        "for i in range(len(q1_sequence)):\n",
        "    embedding = np.zeros(300)\n",
        "    for j in range(len(q1_sequence[i])):\n",
        "        embedding += embedding_matrix[q1_sequence[i][j]]\n",
        "    embedding /= len(q1_sequence[i])\n",
        "    q1_embeddings.append(embedding)\n",
        "\n",
        "q2_embeddings = []\n",
        "for i in range(len(q2_sequence)):\n",
        "    embedding = np.zeros(300)\n",
        "    for j in range(len(q2_sequence[i])):\n",
        "        embedding += embedding_matrix[q2_sequence[i][j]]\n",
        "    embedding /= len(q2_sequence[i])\n",
        "    q2_embeddings.append(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qWyeemfhldIk"
      },
      "outputs": [],
      "source": [
        "# change all 0 to 0 1 and 1 to 1 0\n",
        "for i in range(len(is_duplicate)):\n",
        "    if is_duplicate[i] == 0:\n",
        "        is_duplicate[i] = [0,1]\n",
        "    else:\n",
        "        is_duplicate[i] = [1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "W5rc0Sj4ldIl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#split the data into 70-20-10 train-validation-test with random state 42\n",
        "from sklearn.model_selection import train_test_split\n",
        "q1_train, q1_test, q2_train, q2_test, y_train, y_test = train_test_split(q1_embeddings, q2_embeddings, is_duplicate, test_size=0.1, random_state=42)\n",
        "q1_train, q1_val, q2_train, q2_val, y_train, y_val = train_test_split(q1_train, q2_train, y_train, test_size=0.222, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVBDxUA0ldIl",
        "outputId": "96b326af-0525-4c73-94b0-fb999766b10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  [0.36970243 0.63029757]\n",
            "Validation:  [0.36774353 0.63225647]\n",
            "Test:  [0.36907706 0.63092294]\n"
          ]
        }
      ],
      "source": [
        "#print the ratio of positive and negative samples in train, validation and test\n",
        "y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)\n",
        "print(\"Train: \", sum(y_train)/len(y_train))\n",
        "print(\"Validation: \", sum(y_val)/len(y_val))\n",
        "print(\"Test: \", sum(y_test)/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MLni6rjEldIl"
      },
      "outputs": [],
      "source": [
        "def concatenate_embeddings(q1_embeddings, q2_embeddings):\n",
        "    embeddings = np.zeros((len(q1_embeddings), 900))\n",
        "    for i in range(len(q1_embeddings)):\n",
        "        for j in range(0, 300):\n",
        "            embeddings[i][j] = q1_embeddings[i][j] + q2_embeddings[i][j]\n",
        "        for j in range(300, 600):\n",
        "            embeddings[i][j] = q1_embeddings[i][j-300] - q2_embeddings[i][j-300]\n",
        "        for j in range(600, 900):\n",
        "            embeddings[i][j] = q1_embeddings[i][j-600] * q2_embeddings[i][j-600]\n",
        "    return embeddings\n",
        "xtrain_concat = concatenate_embeddings(q1_train, q2_train)\n",
        "xval_concat = concatenate_embeddings(q1_val, q2_val)\n",
        "xtest_concat = concatenate_embeddings(q1_test, q2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0BsqrlH4ldIm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(80790, 900)\n",
            "(283125, 900)\n"
          ]
        }
      ],
      "source": [
        "print(xval_concat.shape)\n",
        "print(xtrain_concat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "R06334g6ldIm"
      },
      "outputs": [],
      "source": [
        "model = CBOW(embedding_matrix, embedding_matrix.shape[0], loss=\"binary_crossentropy\", epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(xtrain_concat, xval_concat, y_train, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 300)               270300    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 300)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               60200     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               20100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 350,802\n",
            "Trainable params: 350,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.get_model_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZGI818eldIm",
        "outputId": "bb3f6031-d701-4a30-bb69-7dc0370ad172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "4424/4424 [==============================] - 43s 9ms/step - loss: 0.6159 - accuracy: 0.6393 - val_loss: 0.5905 - val_accuracy: 0.6801\n",
            "Epoch 2/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.5879 - accuracy: 0.6732 - val_loss: 0.5772 - val_accuracy: 0.6896\n",
            "Epoch 3/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.5754 - accuracy: 0.6850 - val_loss: 0.5671 - val_accuracy: 0.6936\n",
            "Epoch 4/150\n",
            "4424/4424 [==============================] - 41s 9ms/step - loss: 0.5656 - accuracy: 0.6920 - val_loss: 0.5579 - val_accuracy: 0.6912\n",
            "Epoch 5/150\n",
            "4424/4424 [==============================] - 42s 9ms/step - loss: 0.5582 - accuracy: 0.6983 - val_loss: 0.5661 - val_accuracy: 0.6928\n",
            "Epoch 6/150\n",
            "4424/4424 [==============================] - 42s 10ms/step - loss: 0.5522 - accuracy: 0.7026 - val_loss: 0.5524 - val_accuracy: 0.6993\n",
            "Epoch 7/150\n",
            "4424/4424 [==============================] - 42s 9ms/step - loss: 0.5491 - accuracy: 0.7038 - val_loss: 0.5353 - val_accuracy: 0.7194\n",
            "Epoch 8/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.5420 - accuracy: 0.7100 - val_loss: 0.5312 - val_accuracy: 0.7181\n",
            "Epoch 9/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.5362 - accuracy: 0.7140 - val_loss: 0.5306 - val_accuracy: 0.7204\n",
            "Epoch 10/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.5315 - accuracy: 0.7159 - val_loss: 0.5300 - val_accuracy: 0.7163\n",
            "Epoch 11/150\n",
            "4424/4424 [==============================] - 42s 9ms/step - loss: 0.5267 - accuracy: 0.7201 - val_loss: 0.5385 - val_accuracy: 0.6955\n",
            "Epoch 12/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.5227 - accuracy: 0.7224 - val_loss: 0.5117 - val_accuracy: 0.7311\n",
            "Epoch 13/150\n",
            "4424/4424 [==============================] - 45s 10ms/step - loss: 0.5192 - accuracy: 0.7244 - val_loss: 0.5135 - val_accuracy: 0.7315\n",
            "Epoch 14/150\n",
            "4424/4424 [==============================] - 42s 10ms/step - loss: 0.5146 - accuracy: 0.7280 - val_loss: 0.5100 - val_accuracy: 0.7347\n",
            "Epoch 15/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.5110 - accuracy: 0.7304 - val_loss: 0.5120 - val_accuracy: 0.7236\n",
            "Epoch 16/150\n",
            "4424/4424 [==============================] - 42s 10ms/step - loss: 0.5078 - accuracy: 0.7319 - val_loss: 0.4975 - val_accuracy: 0.7425\n",
            "Epoch 17/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.5057 - accuracy: 0.7336 - val_loss: 0.4967 - val_accuracy: 0.7413\n",
            "Epoch 18/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.5035 - accuracy: 0.7357 - val_loss: 0.5012 - val_accuracy: 0.7385\n",
            "Epoch 19/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4995 - accuracy: 0.7383 - val_loss: 0.5061 - val_accuracy: 0.7415\n",
            "Epoch 20/150\n",
            "4424/4424 [==============================] - 42s 9ms/step - loss: 0.4978 - accuracy: 0.7396 - val_loss: 0.5120 - val_accuracy: 0.7288\n",
            "Epoch 21/150\n",
            "4424/4424 [==============================] - 42s 10ms/step - loss: 0.4951 - accuracy: 0.7413 - val_loss: 0.4913 - val_accuracy: 0.7479\n",
            "Epoch 22/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4939 - accuracy: 0.7426 - val_loss: 0.4943 - val_accuracy: 0.7445\n",
            "Epoch 23/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4916 - accuracy: 0.7441 - val_loss: 0.4843 - val_accuracy: 0.7535\n",
            "Epoch 24/150\n",
            "4424/4424 [==============================] - 42s 9ms/step - loss: 0.4898 - accuracy: 0.7453 - val_loss: 0.4842 - val_accuracy: 0.7525\n",
            "Epoch 25/150\n",
            "4424/4424 [==============================] - 42s 9ms/step - loss: 0.4881 - accuracy: 0.7459 - val_loss: 0.4999 - val_accuracy: 0.7366\n",
            "Epoch 26/150\n",
            "4424/4424 [==============================] - 42s 10ms/step - loss: 0.4866 - accuracy: 0.7475 - val_loss: 0.4890 - val_accuracy: 0.7439\n",
            "Epoch 27/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4844 - accuracy: 0.7483 - val_loss: 0.4769 - val_accuracy: 0.7555\n",
            "Epoch 28/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4822 - accuracy: 0.7502 - val_loss: 0.4801 - val_accuracy: 0.7545\n",
            "Epoch 29/150\n",
            "4424/4424 [==============================] - 42s 10ms/step - loss: 0.4807 - accuracy: 0.7508 - val_loss: 0.4965 - val_accuracy: 0.7377\n",
            "Epoch 30/150\n",
            "4424/4424 [==============================] - 42s 10ms/step - loss: 0.4797 - accuracy: 0.7525 - val_loss: 0.4752 - val_accuracy: 0.7583\n",
            "Epoch 31/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4771 - accuracy: 0.7543 - val_loss: 0.4709 - val_accuracy: 0.7632\n",
            "Epoch 32/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4768 - accuracy: 0.7535 - val_loss: 0.4733 - val_accuracy: 0.7608\n",
            "Epoch 33/150\n",
            "4424/4424 [==============================] - 47s 11ms/step - loss: 0.4746 - accuracy: 0.7555 - val_loss: 0.4744 - val_accuracy: 0.7577\n",
            "Epoch 34/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4729 - accuracy: 0.7571 - val_loss: 0.4718 - val_accuracy: 0.7594\n",
            "Epoch 35/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4712 - accuracy: 0.7572 - val_loss: 0.4764 - val_accuracy: 0.7568\n",
            "Epoch 36/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4700 - accuracy: 0.7583 - val_loss: 0.5055 - val_accuracy: 0.7304\n",
            "Epoch 37/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4696 - accuracy: 0.7583 - val_loss: 0.4727 - val_accuracy: 0.7559\n",
            "Epoch 38/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4678 - accuracy: 0.7597 - val_loss: 0.4708 - val_accuracy: 0.7598\n",
            "Epoch 39/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4663 - accuracy: 0.7606 - val_loss: 0.4739 - val_accuracy: 0.7607\n",
            "Epoch 40/150\n",
            "4424/4424 [==============================] - 45s 10ms/step - loss: 0.4655 - accuracy: 0.7605 - val_loss: 0.4660 - val_accuracy: 0.7647\n",
            "Epoch 41/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4643 - accuracy: 0.7617 - val_loss: 0.4691 - val_accuracy: 0.7608\n",
            "Epoch 42/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4624 - accuracy: 0.7631 - val_loss: 0.4621 - val_accuracy: 0.7676\n",
            "Epoch 43/150\n",
            "4424/4424 [==============================] - 50s 11ms/step - loss: 0.4623 - accuracy: 0.7629 - val_loss: 0.4642 - val_accuracy: 0.7661\n",
            "Epoch 44/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4602 - accuracy: 0.7651 - val_loss: 0.4933 - val_accuracy: 0.7420\n",
            "Epoch 45/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4582 - accuracy: 0.7655 - val_loss: 0.4678 - val_accuracy: 0.7645\n",
            "Epoch 46/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4575 - accuracy: 0.7677 - val_loss: 0.4629 - val_accuracy: 0.7658\n",
            "Epoch 47/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4563 - accuracy: 0.7667 - val_loss: 0.4616 - val_accuracy: 0.7682\n",
            "Epoch 48/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4555 - accuracy: 0.7675 - val_loss: 0.4613 - val_accuracy: 0.7680\n",
            "Epoch 49/150\n",
            "4424/4424 [==============================] - 45s 10ms/step - loss: 0.4540 - accuracy: 0.7685 - val_loss: 0.4584 - val_accuracy: 0.7687\n",
            "Epoch 50/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4522 - accuracy: 0.7699 - val_loss: 0.4624 - val_accuracy: 0.7637\n",
            "Epoch 51/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4522 - accuracy: 0.7697 - val_loss: 0.4563 - val_accuracy: 0.7712\n",
            "Epoch 52/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4501 - accuracy: 0.7707 - val_loss: 0.4553 - val_accuracy: 0.7733\n",
            "Epoch 53/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4493 - accuracy: 0.7721 - val_loss: 0.4544 - val_accuracy: 0.7724\n",
            "Epoch 54/150\n",
            "4424/4424 [==============================] - 45s 10ms/step - loss: 0.4475 - accuracy: 0.7730 - val_loss: 0.4539 - val_accuracy: 0.7739\n",
            "Epoch 55/150\n",
            "4424/4424 [==============================] - 75s 17ms/step - loss: 0.4465 - accuracy: 0.7737 - val_loss: 0.4587 - val_accuracy: 0.7717\n",
            "Epoch 56/150\n",
            "4424/4424 [==============================] - 183s 41ms/step - loss: 0.4456 - accuracy: 0.7735 - val_loss: 0.4609 - val_accuracy: 0.7662\n",
            "Epoch 57/150\n",
            "4424/4424 [==============================] - 138s 31ms/step - loss: 0.4449 - accuracy: 0.7741 - val_loss: 0.4600 - val_accuracy: 0.7675\n",
            "Epoch 58/150\n",
            "4424/4424 [==============================] - 172s 39ms/step - loss: 0.4445 - accuracy: 0.7747 - val_loss: 0.4599 - val_accuracy: 0.7703\n",
            "Epoch 59/150\n",
            "4424/4424 [==============================] - 156s 35ms/step - loss: 0.4434 - accuracy: 0.7755 - val_loss: 0.4516 - val_accuracy: 0.7755\n",
            "Epoch 60/150\n",
            "4424/4424 [==============================] - 86s 19ms/step - loss: 0.4426 - accuracy: 0.7763 - val_loss: 0.4579 - val_accuracy: 0.7758\n",
            "Epoch 61/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4413 - accuracy: 0.7770 - val_loss: 0.4591 - val_accuracy: 0.7699\n",
            "Epoch 62/150\n",
            "4424/4424 [==============================] - 113s 25ms/step - loss: 0.4411 - accuracy: 0.7771 - val_loss: 0.4505 - val_accuracy: 0.7771\n",
            "Epoch 63/150\n",
            "4424/4424 [==============================] - 196s 44ms/step - loss: 0.4400 - accuracy: 0.7773 - val_loss: 0.4533 - val_accuracy: 0.7724\n",
            "Epoch 64/150\n",
            "4424/4424 [==============================] - 150s 34ms/step - loss: 0.4385 - accuracy: 0.7782 - val_loss: 0.4604 - val_accuracy: 0.7650\n",
            "Epoch 65/150\n",
            "4424/4424 [==============================] - 203s 46ms/step - loss: 0.4384 - accuracy: 0.7782 - val_loss: 0.4483 - val_accuracy: 0.7786\n",
            "Epoch 66/150\n",
            "4424/4424 [==============================] - 161s 36ms/step - loss: 0.4364 - accuracy: 0.7796 - val_loss: 0.4500 - val_accuracy: 0.7772\n",
            "Epoch 67/150\n",
            "4424/4424 [==============================] - 46s 10ms/step - loss: 0.4356 - accuracy: 0.7803 - val_loss: 0.4497 - val_accuracy: 0.7759\n",
            "Epoch 68/150\n",
            "4424/4424 [==============================] - 101s 23ms/step - loss: 0.4363 - accuracy: 0.7797 - val_loss: 0.4462 - val_accuracy: 0.7785\n",
            "Epoch 69/150\n",
            "4424/4424 [==============================] - 145s 33ms/step - loss: 0.4347 - accuracy: 0.7810 - val_loss: 0.4535 - val_accuracy: 0.7766\n",
            "Epoch 70/150\n",
            "4424/4424 [==============================] - 87s 20ms/step - loss: 0.4335 - accuracy: 0.7810 - val_loss: 0.4455 - val_accuracy: 0.7795\n",
            "Epoch 71/150\n",
            "4424/4424 [==============================] - 173s 39ms/step - loss: 0.4335 - accuracy: 0.7810 - val_loss: 0.4464 - val_accuracy: 0.7760\n",
            "Epoch 72/150\n",
            "4424/4424 [==============================] - 96s 22ms/step - loss: 0.4323 - accuracy: 0.7822 - val_loss: 0.4432 - val_accuracy: 0.7813\n",
            "Epoch 73/150\n",
            "4424/4424 [==============================] - 141s 32ms/step - loss: 0.4314 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7551\n",
            "Epoch 74/150\n",
            "4424/4424 [==============================] - 98s 22ms/step - loss: 0.4303 - accuracy: 0.7838 - val_loss: 0.4501 - val_accuracy: 0.7727\n",
            "Epoch 75/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4298 - accuracy: 0.7837 - val_loss: 0.4568 - val_accuracy: 0.7733\n",
            "Epoch 76/150\n",
            "4424/4424 [==============================] - 134s 30ms/step - loss: 0.4297 - accuracy: 0.7841 - val_loss: 0.4462 - val_accuracy: 0.7769\n",
            "Epoch 77/150\n",
            "4424/4424 [==============================] - 151s 34ms/step - loss: 0.4277 - accuracy: 0.7850 - val_loss: 0.4484 - val_accuracy: 0.7742\n",
            "Epoch 78/150\n",
            "4424/4424 [==============================] - 193s 44ms/step - loss: 0.4272 - accuracy: 0.7855 - val_loss: 0.4431 - val_accuracy: 0.7810\n",
            "Epoch 79/150\n",
            "4424/4424 [==============================] - 166s 38ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.4465 - val_accuracy: 0.7809\n",
            "Epoch 80/150\n",
            "4424/4424 [==============================] - 117s 27ms/step - loss: 0.4253 - accuracy: 0.7868 - val_loss: 0.4657 - val_accuracy: 0.7663\n",
            "Epoch 81/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4246 - accuracy: 0.7874 - val_loss: 0.4448 - val_accuracy: 0.7831\n",
            "Epoch 82/150\n",
            "4424/4424 [==============================] - 46s 10ms/step - loss: 0.4256 - accuracy: 0.7863 - val_loss: 0.4411 - val_accuracy: 0.7828\n",
            "Epoch 83/150\n",
            "4424/4424 [==============================] - 44s 10ms/step - loss: 0.4233 - accuracy: 0.7875 - val_loss: 0.4492 - val_accuracy: 0.7739\n",
            "Epoch 84/150\n",
            "4424/4424 [==============================] - 47s 11ms/step - loss: 0.4231 - accuracy: 0.7877 - val_loss: 0.4460 - val_accuracy: 0.7785\n",
            "Epoch 85/150\n",
            "4424/4424 [==============================] - 97s 22ms/step - loss: 0.4219 - accuracy: 0.7879 - val_loss: 0.4471 - val_accuracy: 0.7756\n",
            "Epoch 86/150\n",
            "4424/4424 [==============================] - 60s 14ms/step - loss: 0.4215 - accuracy: 0.7887 - val_loss: 0.4425 - val_accuracy: 0.7829\n",
            "Epoch 87/150\n",
            "4424/4424 [==============================] - 174s 39ms/step - loss: 0.4203 - accuracy: 0.7889 - val_loss: 0.4435 - val_accuracy: 0.7823\n",
            "Epoch 88/150\n",
            "4424/4424 [==============================] - 170s 38ms/step - loss: 0.4202 - accuracy: 0.7889 - val_loss: 0.4501 - val_accuracy: 0.7799\n",
            "Epoch 89/150\n",
            "4424/4424 [==============================] - 109s 25ms/step - loss: 0.4188 - accuracy: 0.7904 - val_loss: 0.4431 - val_accuracy: 0.7826\n",
            "Epoch 90/150\n",
            "4424/4424 [==============================] - 189s 43ms/step - loss: 0.4175 - accuracy: 0.7908 - val_loss: 0.4434 - val_accuracy: 0.7797\n",
            "Epoch 91/150\n",
            "4424/4424 [==============================] - 45s 10ms/step - loss: 0.4174 - accuracy: 0.7904 - val_loss: 0.4408 - val_accuracy: 0.7805\n",
            "Epoch 92/150\n",
            "4424/4424 [==============================] - 108s 24ms/step - loss: 0.4175 - accuracy: 0.7912 - val_loss: 0.4408 - val_accuracy: 0.7842\n",
            "Epoch 93/150\n",
            "4424/4424 [==============================] - 63s 14ms/step - loss: 0.4161 - accuracy: 0.7916 - val_loss: 0.4446 - val_accuracy: 0.7793\n",
            "Epoch 94/150\n",
            "4424/4424 [==============================] - 156s 35ms/step - loss: 0.4160 - accuracy: 0.7915 - val_loss: 0.4433 - val_accuracy: 0.7790\n",
            "Epoch 95/150\n",
            "4424/4424 [==============================] - 145s 33ms/step - loss: 0.4140 - accuracy: 0.7923 - val_loss: 0.4406 - val_accuracy: 0.7840\n",
            "Epoch 96/150\n",
            "4424/4424 [==============================] - 147s 33ms/step - loss: 0.4130 - accuracy: 0.7930 - val_loss: 0.4554 - val_accuracy: 0.7767\n",
            "Epoch 97/150\n",
            "4424/4424 [==============================] - 128s 29ms/step - loss: 0.4132 - accuracy: 0.7938 - val_loss: 0.4450 - val_accuracy: 0.7825\n",
            "Epoch 98/150\n",
            "4424/4424 [==============================] - 94s 21ms/step - loss: 0.4129 - accuracy: 0.7934 - val_loss: 0.4389 - val_accuracy: 0.7855\n",
            "Epoch 99/150\n",
            "4424/4424 [==============================] - 143s 32ms/step - loss: 0.4123 - accuracy: 0.7942 - val_loss: 0.4399 - val_accuracy: 0.7834\n",
            "Epoch 100/150\n",
            "4424/4424 [==============================] - 47s 11ms/step - loss: 0.4109 - accuracy: 0.7956 - val_loss: 0.4348 - val_accuracy: 0.7875\n",
            "Epoch 101/150\n",
            "4424/4424 [==============================] - 89s 20ms/step - loss: 0.4109 - accuracy: 0.7942 - val_loss: 0.4454 - val_accuracy: 0.7861\n",
            "Epoch 102/150\n",
            "4424/4424 [==============================] - 119s 27ms/step - loss: 0.4096 - accuracy: 0.7957 - val_loss: 0.4385 - val_accuracy: 0.7856\n",
            "Epoch 103/150\n",
            "4424/4424 [==============================] - 130s 29ms/step - loss: 0.4099 - accuracy: 0.7954 - val_loss: 0.4432 - val_accuracy: 0.7793\n",
            "Epoch 104/150\n",
            "4424/4424 [==============================] - 169s 38ms/step - loss: 0.4091 - accuracy: 0.7962 - val_loss: 0.4475 - val_accuracy: 0.7796\n",
            "Epoch 105/150\n",
            "4424/4424 [==============================] - 206s 46ms/step - loss: 0.4086 - accuracy: 0.7960 - val_loss: 0.4489 - val_accuracy: 0.7811\n",
            "Epoch 106/150\n",
            "4424/4424 [==============================] - 48s 11ms/step - loss: 0.4092 - accuracy: 0.7955 - val_loss: 0.4435 - val_accuracy: 0.7803\n",
            "Epoch 107/150\n",
            "4424/4424 [==============================] - 165s 37ms/step - loss: 0.4076 - accuracy: 0.7964 - val_loss: 0.4412 - val_accuracy: 0.7848\n",
            "Epoch 108/150\n",
            "4424/4424 [==============================] - 111s 25ms/step - loss: 0.4071 - accuracy: 0.7965 - val_loss: 0.4373 - val_accuracy: 0.7863\n",
            "Epoch 109/150\n",
            "4424/4424 [==============================] - 156s 35ms/step - loss: 0.4063 - accuracy: 0.7978 - val_loss: 0.4377 - val_accuracy: 0.7832\n",
            "Epoch 110/150\n",
            "4424/4424 [==============================] - 154s 35ms/step - loss: 0.4050 - accuracy: 0.7975 - val_loss: 0.4358 - val_accuracy: 0.7877\n",
            "Epoch 111/150\n",
            "4424/4424 [==============================] - 155s 35ms/step - loss: 0.4053 - accuracy: 0.7976 - val_loss: 0.4424 - val_accuracy: 0.7869\n",
            "Epoch 112/150\n",
            "4424/4424 [==============================] - 142s 32ms/step - loss: 0.4044 - accuracy: 0.7985 - val_loss: 0.4400 - val_accuracy: 0.7848\n",
            "Epoch 113/150\n",
            "4424/4424 [==============================] - 159s 36ms/step - loss: 0.4034 - accuracy: 0.7999 - val_loss: 0.4366 - val_accuracy: 0.7874\n",
            "Epoch 114/150\n",
            "4424/4424 [==============================] - 45s 10ms/step - loss: 0.4036 - accuracy: 0.7990 - val_loss: 0.4402 - val_accuracy: 0.7844\n",
            "Epoch 115/150\n",
            "4424/4424 [==============================] - 79s 18ms/step - loss: 0.4025 - accuracy: 0.8006 - val_loss: 0.4424 - val_accuracy: 0.7829\n",
            "Epoch 116/150\n",
            "4424/4424 [==============================] - 76s 17ms/step - loss: 0.4030 - accuracy: 0.7994 - val_loss: 0.4362 - val_accuracy: 0.7843\n",
            "Epoch 117/150\n",
            "4424/4424 [==============================] - 180s 41ms/step - loss: 0.4017 - accuracy: 0.7996 - val_loss: 0.4375 - val_accuracy: 0.7852\n",
            "Epoch 118/150\n",
            "4424/4424 [==============================] - 148s 33ms/step - loss: 0.4005 - accuracy: 0.8008 - val_loss: 0.4391 - val_accuracy: 0.7884\n",
            "Epoch 119/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.4003 - accuracy: 0.8003 - val_loss: 0.4366 - val_accuracy: 0.7858\n",
            "Epoch 120/150\n",
            "4424/4424 [==============================] - 121s 27ms/step - loss: 0.3999 - accuracy: 0.8005 - val_loss: 0.4457 - val_accuracy: 0.7860\n",
            "Epoch 121/150\n",
            "4424/4424 [==============================] - 119s 27ms/step - loss: 0.4002 - accuracy: 0.8012 - val_loss: 0.4357 - val_accuracy: 0.7859\n",
            "Epoch 122/150\n",
            "4424/4424 [==============================] - 75s 17ms/step - loss: 0.4000 - accuracy: 0.8008 - val_loss: 0.4360 - val_accuracy: 0.7889\n",
            "Epoch 123/150\n",
            "4424/4424 [==============================] - 148s 34ms/step - loss: 0.3990 - accuracy: 0.8018 - val_loss: 0.4402 - val_accuracy: 0.7819\n",
            "Epoch 124/150\n",
            "4424/4424 [==============================] - 191s 43ms/step - loss: 0.3979 - accuracy: 0.8028 - val_loss: 0.4394 - val_accuracy: 0.7879\n",
            "Epoch 125/150\n",
            "4424/4424 [==============================] - 187s 42ms/step - loss: 0.3977 - accuracy: 0.8026 - val_loss: 0.4297 - val_accuracy: 0.7917\n",
            "Epoch 126/150\n",
            "4424/4424 [==============================] - 130s 29ms/step - loss: 0.3968 - accuracy: 0.8031 - val_loss: 0.4387 - val_accuracy: 0.7899\n",
            "Epoch 127/150\n",
            "4424/4424 [==============================] - 92s 21ms/step - loss: 0.3969 - accuracy: 0.8025 - val_loss: 0.4353 - val_accuracy: 0.7901\n",
            "Epoch 128/150\n",
            "4424/4424 [==============================] - 183s 41ms/step - loss: 0.3963 - accuracy: 0.8031 - val_loss: 0.4408 - val_accuracy: 0.7848\n",
            "Epoch 129/150\n",
            "4424/4424 [==============================] - 106s 24ms/step - loss: 0.3951 - accuracy: 0.8036 - val_loss: 0.4346 - val_accuracy: 0.7893\n",
            "Epoch 130/150\n",
            "4424/4424 [==============================] - 201s 45ms/step - loss: 0.3948 - accuracy: 0.8043 - val_loss: 0.4369 - val_accuracy: 0.7897\n",
            "Epoch 131/150\n",
            "4424/4424 [==============================] - 151s 34ms/step - loss: 0.3951 - accuracy: 0.8036 - val_loss: 0.4425 - val_accuracy: 0.7880\n",
            "Epoch 132/150\n",
            "4424/4424 [==============================] - 136s 31ms/step - loss: 0.3937 - accuracy: 0.8048 - val_loss: 0.4437 - val_accuracy: 0.7853\n",
            "Epoch 133/150\n",
            "4424/4424 [==============================] - 164s 37ms/step - loss: 0.3944 - accuracy: 0.8036 - val_loss: 0.4389 - val_accuracy: 0.7828\n",
            "Epoch 134/150\n",
            "4424/4424 [==============================] - 207s 47ms/step - loss: 0.3938 - accuracy: 0.8040 - val_loss: 0.4370 - val_accuracy: 0.7900\n",
            "Epoch 135/150\n",
            "4424/4424 [==============================] - 47s 11ms/step - loss: 0.3925 - accuracy: 0.8057 - val_loss: 0.4363 - val_accuracy: 0.7874\n",
            "Epoch 136/150\n",
            "4424/4424 [==============================] - 88s 20ms/step - loss: 0.3925 - accuracy: 0.8054 - val_loss: 0.4416 - val_accuracy: 0.7835\n",
            "Epoch 137/150\n",
            "4424/4424 [==============================] - 107s 24ms/step - loss: 0.3916 - accuracy: 0.8056 - val_loss: 0.4411 - val_accuracy: 0.7886\n",
            "Epoch 138/150\n",
            "4424/4424 [==============================] - 43s 10ms/step - loss: 0.3910 - accuracy: 0.8070 - val_loss: 0.4376 - val_accuracy: 0.7905\n",
            "Epoch 139/150\n",
            "4424/4424 [==============================] - 117s 26ms/step - loss: 0.3912 - accuracy: 0.8061 - val_loss: 0.4380 - val_accuracy: 0.7881\n",
            "Epoch 140/150\n",
            "4424/4424 [==============================] - 118s 27ms/step - loss: 0.3908 - accuracy: 0.8066 - val_loss: 0.4409 - val_accuracy: 0.7915\n",
            "Epoch 141/150\n",
            "4424/4424 [==============================] - 135s 30ms/step - loss: 0.3900 - accuracy: 0.8074 - val_loss: 0.4336 - val_accuracy: 0.7908\n",
            "Epoch 142/150\n",
            "4424/4424 [==============================] - 67s 15ms/step - loss: 0.3891 - accuracy: 0.8076 - val_loss: 0.4479 - val_accuracy: 0.7923\n",
            "Epoch 143/150\n",
            "4424/4424 [==============================] - 134s 30ms/step - loss: 0.3890 - accuracy: 0.8080 - val_loss: 0.4493 - val_accuracy: 0.7865\n",
            "Epoch 144/150\n",
            "4424/4424 [==============================] - 150s 34ms/step - loss: 0.3884 - accuracy: 0.8073 - val_loss: 0.4396 - val_accuracy: 0.7913\n",
            "Epoch 145/150\n",
            "4424/4424 [==============================] - 113s 25ms/step - loss: 0.3889 - accuracy: 0.8071 - val_loss: 0.4354 - val_accuracy: 0.7908\n",
            "Epoch 146/150\n",
            "4424/4424 [==============================] - 132s 30ms/step - loss: 0.3874 - accuracy: 0.8090 - val_loss: 0.4393 - val_accuracy: 0.7918\n",
            "Epoch 147/150\n",
            "4424/4424 [==============================] - 151s 34ms/step - loss: 0.3869 - accuracy: 0.8083 - val_loss: 0.4473 - val_accuracy: 0.7853\n",
            "Epoch 148/150\n",
            "4424/4424 [==============================] - 89s 20ms/step - loss: 0.3857 - accuracy: 0.8097 - val_loss: 0.4391 - val_accuracy: 0.8001\n",
            "Epoch 149/150\n",
            "4424/4424 [==============================] - 114s 26ms/step - loss: 0.3865 - accuracy: 0.8087 - val_loss: 0.4335 - val_accuracy: 0.8017\n",
            "Epoch 150/150\n",
            "4424/4424 [==============================] - 57s 13ms/step - loss: 0.3855 - accuracy: 0.8101 - val_loss: 0.4433 - val_accuracy: 0.79.94\n"
          ]
        }
      ],
      "source": [
        "model.model.fit(xtrain_concat, y_train, epochs=150, batch_size=32, validation_batch_size=16, validation_data=(xval_concat, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pPrGV3vldIm",
        "outputId": "6458e409-29b2-45be-f9b1-8c2ea1bd8bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1264/1264 [==============================] - 4s 3ms/step\n",
            "Accuracy:  0.8065268572559105\n",
            "F1 Score:  0.8336609241916214\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(xtest_concat)\n",
        "y_pred1d = []\n",
        "for i in range(len(y_pred)):\n",
        "    if(y_pred[i][0] > y_pred[i][1]):\n",
        "        y_pred1d.append(0)\n",
        "    else:\n",
        "        y_pred1d.append(1)\n",
        "\n",
        "y_test1d = []\n",
        "for i in range(len(y_test)):\n",
        "    if(y_test[i][0] > y_test[i][1]):\n",
        "        y_test1d.append(0)\n",
        "    else:\n",
        "        y_test1d.append(1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "print(\"Accuracy: \", accuracy_score(y_test1d, y_pred1d))\n",
        "print(\"F1 Score: \", f1_score(y_test1d, y_pred1d))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqkuz30cldIn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
