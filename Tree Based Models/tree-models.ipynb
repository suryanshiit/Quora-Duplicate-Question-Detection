{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_6dY1bIljF84"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from string import punctuation\n",
        "import numpy as np \n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "stopwords = set( set(nltk.corpus.stopwords.words('english')).union(set(punctuation)) )\n",
        "\n",
        "def preprocess_tokenize(text):\n",
        "    tokens = word_tokenize(re.sub(r'[^\\x00-\\x7F]+', ' ', text.lower()))\n",
        "    tokens_without_stopwords = [word for word in tokens if word not in stopwords]\n",
        "    return ' '.join(tokens_without_stopwords)\n",
        "\n",
        "preprocessor = np.vectorize(preprocess_tokenize)\n",
        "\n",
        "def preprocess_tree(q1,q2,dup):\n",
        "    q1_preprocessed, q2_preprocessed = preprocessor(q1), preprocessor(q2)\n",
        "    df = pd.DataFrame({'question1': q1_preprocessed, 'question2': q2_preprocessed, 'is_duplicate': dup})\n",
        "    df.to_csv('preprocessed_neural.csv', index=False)\n",
        "    return q1_preprocessed, q2_preprocessed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Gc1_IljIJo",
        "outputId": "4d2cd028-2688-4330-b960-56ed1d86a30a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcLUtWufjT6Q",
        "outputId": "73a29bb7-3ccd-44ad-b367-0fb61bb132fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"drive/MyDrive/preprocessed_neural.csv\")\n",
        "df.dropna(how='any').reset_index(drop=True)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VqpKstvrjsag",
        "outputId": "b08218d3-0dd4-4d61-d991-76d14cbf6d47"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           question1  \\\n",
              "0          step step guide invest share market india   \n",
              "1                    story kohinoor kohinoor diamond   \n",
              "2       increase speed internet connection using vpn   \n",
              "3                              mentally lonely solve   \n",
              "4  one dissolve water quikly sugar salt methane c...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0                step step guide invest share market             0  \n",
              "1  would happen indian government stole kohinoor ...             0  \n",
              "2               internet speed increased hacking dns             0  \n",
              "3           find remainder math2324math divided 2423             0  \n",
              "4                      fish would survive salt water             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddb5e08e-5c16-4e0c-be54-2910fd7ab6f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>step step guide invest share market india</td>\n",
              "      <td>step step guide invest share market</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>story kohinoor kohinoor diamond</td>\n",
              "      <td>would happen indian government stole kohinoor ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>increase speed internet connection using vpn</td>\n",
              "      <td>internet speed increased hacking dns</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mentally lonely solve</td>\n",
              "      <td>find remainder math2324math divided 2423</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
              "      <td>fish would survive salt water</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddb5e08e-5c16-4e0c-be54-2910fd7ab6f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddb5e08e-5c16-4e0c-be54-2910fd7ab6f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddb5e08e-5c16-4e0c-be54-2910fd7ab6f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_length_feature(question1, question2, vector):\n",
        "    if (type(question1) is not float):\n",
        "        l1 = len(question1.split())\n",
        "    else:\n",
        "        l1 = 1\n",
        "    if(type(question2) is not float):\n",
        "        l2 = len(question2.split())\n",
        "    else:\n",
        "        l2 = 1\n",
        "    \n",
        "    if(l2 == 0):\n",
        "        l2 = 1\n",
        "    vector.append(l1)\n",
        "    vector.append(l2)\n",
        "    vector.append(l1-l2)\n",
        "    vector.append(l1/l2)\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "OWN2_qiWj3nw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count_lowercased(question1, question2, vector):\n",
        "\n",
        "    q1 = []\n",
        "    q2 = []\n",
        "\n",
        "    for word in word_tokenize(question1):\n",
        "        if word.islower():\n",
        "            q1.append(word)\n",
        "    \n",
        "    for word in word_tokenize(question2):\n",
        "        if word.islower():\n",
        "            q2.append(word)\n",
        "  \n",
        "\n",
        "    count = len(set(q1) & set(q2))\n",
        "\n",
        "    vector.append(count)\n",
        "    vector.append(count/237)\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "MtWpAb2UkD5D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count_lowercased_without_stopwords(question1, question2, vector):\n",
        "    q1 = []\n",
        "    q2 = []\n",
        "\n",
        "    for word in word_tokenize(question1):\n",
        "        if word.islower() and word not in stopwords:\n",
        "            q1.append(word)\n",
        "    \n",
        "    for word in word_tokenize(question2):\n",
        "        if word.islower() and word not in stopwords:\n",
        "            q2.append(word)\n",
        "\n",
        "\n",
        "    count = len(set(q1) & set(q2))\n",
        "\n",
        "    vector.append(count)\n",
        "    vector.append(count/237)\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "O6YCLdBlkF2B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def same_last_words(question1, question2, vector):\n",
        "    q1 = []\n",
        "    q2 = []\n",
        "\n",
        "    for word in word_tokenize(question1):\n",
        "        q1.append(word)\n",
        "    \n",
        "    for word in word_tokenize(question2):\n",
        "        q2.append(word)\n",
        "    \n",
        "    if(len(q1) > 0 and len(q2) > 0):\n",
        "        vector.append(q1[-1] == q2[-1])\n",
        "    else:\n",
        "        vector.append(False)\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "-hGcjBtvkHT6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count_uppercased(question1, question2, vector):\n",
        "    \n",
        "    q1 = []\n",
        "    q2 = []\n",
        "\n",
        "    for word in word_tokenize(question1):\n",
        "        if word.isupper():\n",
        "            q1.append(word)\n",
        "    \n",
        "    for word in word_tokenize(question2):\n",
        "        if word.isupper():\n",
        "            q2.append(word)\n",
        "\n",
        "\n",
        "    count = len(set(q1) & set(q2))\n",
        "\n",
        "    vector.append(count)\n",
        "    vector.append(count/237)\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "l6pc3xL8kIwU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def same_prefix(question1, question2, vector):\n",
        "    q1 = []\n",
        "    q2 = []\n",
        "    \n",
        "    for word in word_tokenize(question1):\n",
        "        q1.append(word)\n",
        "    \n",
        "    for word in word_tokenize(question2):\n",
        "        q2.append(word)\n",
        "    s=0\n",
        "    for i in range(3):\n",
        "        s = s + (q1[:i]==q2[:i])\n",
        "    vector.append(s) \n",
        "    vector.append(s/237)\n",
        "    s=0\n",
        "    for i in range(4):\n",
        "        s = s + (q1[:i]==q2[:i])\n",
        "    vector.append(s) \n",
        "    vector.append(s/237)\n",
        "    s=0\n",
        "    for i in range(5):\n",
        "        s = s + (q1[:i]==q2[:i])\n",
        "    vector.append(s) \n",
        "    vector.append(s/237)\n",
        "    s=0\n",
        "    for i in range(6):\n",
        "        s = s + (q1[:i]==q2[:i])\n",
        "    vector.append(s) \n",
        "    vector.append(s/237)\n",
        "    \n",
        "    return vector"
      ],
      "metadata": {
        "id": "Xl2QuItWkKNh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def misc_features(question1, question2, vector):\n",
        "    q1 = []\n",
        "    q2 = []\n",
        "\n",
        "    for word in word_tokenize(question1):\n",
        "        q1.append(word)\n",
        "    \n",
        "    for word in word_tokenize(question2):\n",
        "        q2.append(word)\n",
        "    \n",
        "    vector.append('not' in q1)\n",
        "    vector.append('not' in q2)\n",
        "    vector.append('not' in q1 and 'not' in q2)\n",
        "\n",
        "    q11 = []\n",
        "    q21 = []\n",
        "\n",
        "    for word in q1:\n",
        "        if word.isdigit():\n",
        "            q11.append(word)\n",
        "    \n",
        "    for word in q2:\n",
        "        if word.isdigit():\n",
        "            q21.append(word)\n",
        "   \n",
        "    vector.append(len(set(q11) and set(q21)))\n",
        "\n",
        "    q12 = []\n",
        "    q22 = []\n",
        "\n",
        "    for word in q1:\n",
        "        q12.append(ps.stem(word))\n",
        "    \n",
        "    for word in q2:\n",
        "        q22.append(ps.stem(word))\n",
        "\n",
        "    vector.append(len(set(q12) & set(q22)))\n",
        "    vector.append(len(set(q12) & set(q22))/237)\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "bplYbIoKkMCk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_vector(question1, question2):\n",
        "    vector = []\n",
        "    vector = get_length_feature(question1, question2, vector)\n",
        "    vector = get_count_lowercased(question1, question2, vector)\n",
        "    vector = get_count_lowercased_without_stopwords(\n",
        "        question1, question2, vector)\n",
        "    vector = same_last_words(question1, question2, vector)\n",
        "    vector = get_count_uppercased(question1, question2, vector)\n",
        "    vector = same_prefix(question1, question2, vector)\n",
        "    vector = misc_features(question1, question2, vector)\n",
        "    return vector"
      ],
      "metadata": {
        "id": "tvPyHPOEkNlT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, df['is_duplicate'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "KyaHxRrBkQ71"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create feature vectors\n",
        "X_train = X_train.apply(lambda x: create_feature_vector(str(x['question1']), str(x['question2'])), axis=1)\n",
        "X_test = X_test.apply(lambda x: create_feature_vector(str(x['question1']), str(x['question2'])), axis=1)"
      ],
      "metadata": {
        "id": "6aURZjdxkZU5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train.to_list())\n",
        "X_test = np.array(X_test.to_list())\n"
      ],
      "metadata": {
        "id": "XhQ2dSYrnfYL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "\n",
        "def avg_acc_and_f1(no_of_features):\n",
        "  X_train1 = X_train[:,:no_of_features]\n",
        "  X_test1 = X_test[:,:no_of_features]\n",
        "\n",
        "  clf = DecisionTreeClassifier(max_depth=10, min_samples_leaf = 5)\n",
        "  clf.fit(X_train1, y_train)\n",
        "  y_pred = clf.predict(X_test1)\n",
        "  a1 = accuracy_score(y_test, y_pred)\n",
        "  f1 = f1_score(y_test, y_pred)\n",
        "  print(\".\")\n",
        "\n",
        "  clf = RandomForestClassifier(max_depth = None, min_samples_leaf=5, n_estimators=50)\n",
        "  clf.fit(X_train1, y_train)\n",
        "  y_pred = clf.predict(X_test1)\n",
        "  a2 = accuracy_score(y_test, y_pred)\n",
        "  f2 = f1_score(y_test, y_pred)\n",
        "  print(\".\")\n",
        "\n",
        "  clf = GradientBoostingClassifier(max_depth=4, n_estimators=500)\n",
        "  clf.fit(X_train1, y_train)\n",
        "  y_pred = clf.predict(X_test1)\n",
        "  a3 = accuracy_score(y_test, y_pred)\n",
        "  f3 = f1_score(y_test, y_pred)\n",
        "\n",
        "  return np.mean([a1,a2,a3]), np.mean([f1,f2,f3])"
      ],
      "metadata": {
        "id": "0RiJNkcHq0pl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"L\\n\")\n",
        "a, f = avg_acc_and_f1(4)\n",
        "print(\"\\nAccuracy: \",a)\n",
        "print(\"\\nF score: \",f)"
      ],
      "metadata": {
        "id": "3-Q35K3Unm5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705cd423-20b7-45e8-c7f1-a35052e12860"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L\n",
            "\n",
            ".\n",
            ".\n",
            "\n",
            "Accuracy:  0.643203373273485\n",
            "\n",
            "F score:  0.23284812267009902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"L, LC\\n\")\n",
        "a, f = avg_acc_and_f1(6)\n",
        "print(\"\\nAccuracy: \",a)\n",
        "print(\"\\nF score: \",f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Ivw1i2wnAS",
        "outputId": "78091843-983e-4379-91e0-9a8f9efd4027"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L, LC\n",
            "\n",
            ".\n",
            ".\n",
            "\n",
            "Accuracy:  0.6960838866837309\n",
            "\n",
            "F score:  0.5835277745248307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"L, LC, LCXS\\n\")\n",
        "a, f = avg_acc_and_f1(8)\n",
        "print(\"\\nAccuracy: \",a)\n",
        "print(\"\\nF score: \",f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyoSSjRfyRlc",
        "outputId": "f63ce20e-db43-4524-e3e0-6865679f83f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L, LC, LCXS\n",
            "\n",
            ".\n",
            ".\n",
            "\n",
            "Accuracy:  0.6960406078816881\n",
            "\n",
            "F score:  0.5824456784387457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"L, LC, LCXS, LW\\n\")\n",
        "a, f = avg_acc_and_f1(9)\n",
        "print(\"\\nAccuracy: \",a)\n",
        "print(\"\\nF score: \",f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncnagargyf_C",
        "outputId": "6e650a4d-02c2-493b-9d07-e5747681ed8d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L, LC, LCXS, LW\n",
            "\n",
            ".\n",
            ".\n",
            "\n",
            "Accuracy:  0.7233124358546327\n",
            "\n",
            "F score:  0.6200591001459548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"L, LC, LCXS, LW, CAP\\n\")\n",
        "a, f = avg_acc_and_f1(11)\n",
        "print(\"\\nAccuracy: \",a)\n",
        "print(\"\\nF score: \",f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2fdIKG4yi3X",
        "outputId": "c89dae0d-faa4-4560-9b89-a39e63531473"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L, LC, LCXS, LW, CAP\n",
            "\n",
            ".\n",
            ".\n",
            "\n",
            "Accuracy:  0.7233928107727121\n",
            "\n",
            "F score:  0.6210903060972116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"L, LC, LCXS, LW, CAP, PRE\\n\")\n",
        "a, f = avg_acc_and_f1(19)\n",
        "print(\"\\nAccuracy: \",a)\n",
        "print(\"\\nF score: \",f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br0FFZXFym3H",
        "outputId": "42b2a40c-fe68-4b29-b776-3d59daec3460"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L, LC, LCXS, LW, CAP, PRE\n",
            "\n",
            ".\n",
            ".\n",
            "\n",
            "Accuracy:  0.7254021837246973\n",
            "\n",
            "F score:  0.6293394045981935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"L, LC, LCXS, LW, CAP, PRE, M\\n\")\n",
        "a, f = avg_acc_and_f1(25)\n",
        "print(\"\\nAccuracy: \",a)\n",
        "print(\"\\nF score: \",f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY0tCYTxyp-b",
        "outputId": "6b1e31a4-052a-4e11-8dee-4144624b89f4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L, LC, LCXS, LW, CAP, PRE, M\n",
            "\n",
            ".\n",
            ".\n",
            "\n",
            "Accuracy:  0.7400798803031989\n",
            "\n",
            "F score:  0.6513022182739713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3t4XXnC_ytFI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}